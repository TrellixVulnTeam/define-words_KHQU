"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.backendFromV1Alpha1 = exports.buildFromV1Alpha1 = void 0;
const backend = require("../../backend");
const build = require("../../build");
const proto_1 = require("../../../../gcp/proto");
const parsing_1 = require("./parsing");
const error_1 = require("../../../../error");
const functional_1 = require("../../../../functional");
const CHANNEL_NAME_REGEX = new RegExp("(projects\\/" +
    "(?<project>(?:\\d+)|(?:[A-Za-z]+[A-Za-z\\d-]*[A-Za-z\\d]?))\\/)?" +
    "locations\\/" +
    "(?<location>[A-Za-z\\d\\-_]+)\\/" +
    "channels\\/" +
    "(?<channel>[A-Za-z\\d\\-_]+)");
function buildFromV1Alpha1(yaml, project, region, runtime) {
    const manifest = JSON.parse(JSON.stringify(yaml));
    (0, parsing_1.requireKeys)("", manifest, "endpoints");
    (0, parsing_1.assertKeyTypes)("", manifest, {
        specVersion: "string",
        params: "array",
        requiredAPIs: "array",
        endpoints: "object",
    });
    const bd = build.empty();
    bd.params = manifest.params || [];
    bd.requiredAPIs = parseRequiredAPIs(manifest);
    for (const id of Object.keys(manifest.endpoints)) {
        const me = manifest.endpoints[id];
        assertManifestEndpoint(me, id);
        const be = parseEndpointForBuild(id, me, project, region, runtime);
        bd.endpoints[id] = be;
    }
    return bd;
}
exports.buildFromV1Alpha1 = buildFromV1Alpha1;
function backendFromV1Alpha1(yaml, project, region, runtime) {
    const manifest = JSON.parse(JSON.stringify(yaml));
    const bkend = backend.empty();
    bkend.requiredAPIs = parseRequiredAPIs(manifest);
    (0, parsing_1.requireKeys)("", manifest, "endpoints");
    (0, parsing_1.assertKeyTypes)("", manifest, {
        specVersion: "string",
        params: "array",
        requiredAPIs: "array",
        endpoints: "object",
    });
    for (const id of Object.keys(manifest.endpoints)) {
        for (const parsed of parseEndpoints(manifest, id, project, region, runtime)) {
            bkend.endpoints[parsed.region] = bkend.endpoints[parsed.region] || {};
            bkend.endpoints[parsed.region][parsed.id] = parsed;
        }
    }
    return bkend;
}
exports.backendFromV1Alpha1 = backendFromV1Alpha1;
function parseRequiredAPIs(manifest) {
    const requiredAPIs = manifest.requiredAPIs || [];
    for (const { api, reason } of requiredAPIs) {
        if (typeof api !== "string") {
            throw new error_1.FirebaseError(`Invalid api "${JSON.stringify(api)}. Expected string`);
        }
        if (typeof reason !== "string") {
            throw new error_1.FirebaseError(`Invalid reason "${JSON.stringify(reason)} for API ${api}. Expected string`);
        }
    }
    return requiredAPIs;
}
function assertManifestEndpoint(ep, id) {
    const prefix = `endpoints[${id}]`;
    (0, parsing_1.assertKeyTypes)(prefix, ep, {
        region: "array",
        platform: (platform) => backend.AllFunctionsPlatforms.includes(platform),
        entryPoint: "string",
        availableMemoryMb: (mem) => mem === null || backend.isValidMemoryOption(mem),
        maxInstances: "number?",
        minInstances: "number?",
        concurrency: "number?",
        serviceAccount: "string?",
        serviceAccountEmail: "string?",
        timeoutSeconds: "number?",
        vpc: "object?",
        labels: "object?",
        ingressSettings: (setting) => setting === null || backend.AllIngressSettings.includes(setting),
        environmentVariables: "object?",
        secretEnvironmentVariables: "array?",
        httpsTrigger: "object",
        callableTrigger: "object",
        eventTrigger: "object",
        scheduleTrigger: "object",
        taskQueueTrigger: "object",
        blockingTrigger: "object",
        cpu: (cpu) => cpu === null || typeof cpu === "number" || cpu === "gcf_gen1",
    });
    if (ep.vpc) {
        (0, parsing_1.assertKeyTypes)(prefix + ".vpc", ep.vpc, {
            connector: "string",
            egressSettings: (setting) => setting === null || backend.AllVpcEgressSettings.includes(setting),
        });
        (0, parsing_1.requireKeys)(prefix + ".vpc", ep.vpc, "connector");
    }
    let triggerCount = 0;
    if (ep.httpsTrigger) {
        triggerCount++;
    }
    if (ep.callableTrigger) {
        triggerCount++;
    }
    if (ep.eventTrigger) {
        triggerCount++;
    }
    if (ep.scheduleTrigger) {
        triggerCount++;
    }
    if (ep.taskQueueTrigger) {
        triggerCount++;
    }
    if (ep.blockingTrigger) {
        triggerCount++;
    }
    if (!triggerCount) {
        throw new error_1.FirebaseError("Expected trigger in endpoint " + id);
    }
    if (triggerCount > 1) {
        throw new error_1.FirebaseError("Multiple triggers defined for endpoint" + id);
    }
    if (backend.isEventTriggered(ep)) {
        (0, parsing_1.requireKeys)(prefix + ".eventTrigger", ep.eventTrigger, "eventType", "eventFilters");
        (0, parsing_1.assertKeyTypes)(prefix + ".eventTrigger", ep.eventTrigger, {
            eventFilters: "object",
            eventFilterPathPatterns: "object",
            eventType: "string",
            retry: "boolean",
            region: "string",
            serviceAccount: "string?",
            serviceAccountEmail: "string?",
            channel: "string",
        });
    }
    else if (backend.isHttpsTriggered(ep)) {
        (0, parsing_1.assertKeyTypes)(prefix + ".httpsTrigger", ep.httpsTrigger, {
            invoker: "array?",
        });
    }
    else if (backend.isCallableTriggered(ep)) {
    }
    else if (backend.isScheduleTriggered(ep)) {
        (0, parsing_1.assertKeyTypes)(prefix + ".scheduleTrigger", ep.scheduleTrigger, {
            schedule: "string",
            timeZone: "string?",
            retryConfig: "object?",
        });
        (0, parsing_1.assertKeyTypes)(prefix + ".scheduleTrigger.retryConfig", ep.scheduleTrigger.retryConfig || {}, {
            retryCount: "number?",
            maxDoublings: "number?",
            minBackoffSeconds: "number?",
            maxBackoffSeconds: "number?",
            maxRetrySeconds: "number?",
            minBackoffDuration: "string?",
            maxBackoffDuration: "string?",
            maxRetryDuration: "string?",
        });
    }
    else if (backend.isTaskQueueTriggered(ep)) {
        (0, parsing_1.assertKeyTypes)(prefix + ".taskQueueTrigger", ep.taskQueueTrigger, {
            rateLimits: "object?",
            retryConfig: "object?",
            invoker: "array?",
        });
        if (ep.taskQueueTrigger.rateLimits) {
            (0, parsing_1.assertKeyTypes)(prefix + ".taskQueueTrigger.rateLimits", ep.taskQueueTrigger.rateLimits, {
                maxConcurrentDispatches: "number?",
                maxDispatchesPerSecond: "number?",
            });
        }
        if (ep.taskQueueTrigger.retryConfig) {
            (0, parsing_1.assertKeyTypes)(prefix + ".taskQueueTrigger.retryConfig", ep.taskQueueTrigger.retryConfig, {
                maxAttempts: "number?",
                maxRetrySeconds: "number?",
                minBackoffSeconds: "number?",
                maxBackoffSeconds: "number?",
                maxDoublings: "number?",
            });
        }
    }
    else if (backend.isBlockingTriggered(ep)) {
        (0, parsing_1.requireKeys)(prefix + ".blockingTrigger", ep.blockingTrigger, "eventType");
        (0, parsing_1.assertKeyTypes)(prefix + ".blockingTrigger", ep.blockingTrigger, {
            eventType: "string",
            options: "object",
        });
    }
    else {
        throw new error_1.FirebaseError(`Do not recognize trigger type for endpoint ${id}. Try upgrading ` +
            "firebase-tools with npm install -g firebase-tools@latest");
    }
}
function parseEndpointForBuild(id, ep, project, defaultRegion, runtime) {
    var _a;
    let triggered;
    if (backend.isEventTriggered(ep)) {
        const eventTrigger = {
            eventType: ep.eventTrigger.eventType,
            retry: ep.eventTrigger.retry,
        };
        (0, proto_1.renameIfPresent)(eventTrigger, ep.eventTrigger, "serviceAccount", "serviceAccountEmail");
        (0, proto_1.copyIfPresent)(eventTrigger, ep.eventTrigger, "serviceAccount", "eventFilterPathPatterns", "region");
        (0, proto_1.convertIfPresent)(eventTrigger, ep.eventTrigger, "channel", (c) => resolveChannelName(project, c, defaultRegion));
        (0, proto_1.convertIfPresent)(eventTrigger, ep.eventTrigger, "eventFilters", (filters) => {
            const copy = Object.assign({}, filters);
            if (copy["topic"] && !copy["topic"].startsWith("projects/")) {
                copy["topic"] = `projects/${project}/topics/${copy["topic"]}`;
            }
            return copy;
        });
        triggered = { eventTrigger };
    }
    else if (backend.isHttpsTriggered(ep)) {
        triggered = { httpsTrigger: {} };
        (0, proto_1.copyIfPresent)(triggered.httpsTrigger, ep.httpsTrigger, "invoker");
    }
    else if (backend.isCallableTriggered(ep)) {
        triggered = { callableTrigger: {} };
    }
    else if (backend.isScheduleTriggered(ep)) {
        const st = {
            schedule: ep.scheduleTrigger.schedule || "",
            timeZone: (_a = ep.scheduleTrigger.timeZone) !== null && _a !== void 0 ? _a : null,
        };
        if (ep.scheduleTrigger.retryConfig) {
            st.retryConfig = {};
            (0, proto_1.copyIfPresent)(st.retryConfig, ep.scheduleTrigger.retryConfig, "retryCount", "minBackoffSeconds", "maxBackoffSeconds", "maxRetrySeconds", "maxDoublings");
            (0, proto_1.convertIfPresent)(st.retryConfig, ep.scheduleTrigger.retryConfig, "minBackoffSeconds", "minBackoffDuration", (0, functional_1.nullsafeVisitor)(proto_1.secondsFromDuration));
            (0, proto_1.convertIfPresent)(st.retryConfig, ep.scheduleTrigger.retryConfig, "maxBackoffSeconds", "maxBackoffDuration", (0, functional_1.nullsafeVisitor)(proto_1.secondsFromDuration));
            (0, proto_1.convertIfPresent)(st.retryConfig, ep.scheduleTrigger.retryConfig, "maxRetrySeconds", "maxRetryDuration", (0, functional_1.nullsafeVisitor)(proto_1.secondsFromDuration));
        }
        else if (ep.scheduleTrigger.retryConfig === null) {
            st.retryConfig = null;
        }
        triggered = { scheduleTrigger: st };
    }
    else if (backend.isTaskQueueTriggered(ep)) {
        const tq = {};
        if (ep.taskQueueTrigger.invoker) {
            tq.invoker = ep.taskQueueTrigger.invoker;
        }
        else if (ep.taskQueueTrigger.invoker === null) {
            tq.invoker = null;
        }
        if (ep.taskQueueTrigger.retryConfig) {
            tq.retryConfig = Object.assign({}, ep.taskQueueTrigger.retryConfig);
        }
        else if (ep.taskQueueTrigger.retryConfig === null) {
            tq.retryConfig = null;
        }
        if (ep.taskQueueTrigger.rateLimits) {
            tq.rateLimits = Object.assign({}, ep.taskQueueTrigger.rateLimits);
        }
        else if (ep.taskQueueTrigger.rateLimits === null) {
            tq.rateLimits = null;
        }
        triggered = { taskQueueTrigger: tq };
    }
    else if (backend.isBlockingTriggered(ep)) {
        triggered = { blockingTrigger: ep.blockingTrigger };
    }
    else {
        throw new error_1.FirebaseError(`Do not recognize trigger type for endpoint ${id}. Try upgrading ` +
            "firebase-tools with npm install -g firebase-tools@latest");
    }
    const parsed = Object.assign({ platform: ep.platform || "gcfv2", region: ep.region || [defaultRegion], project,
        runtime, entryPoint: ep.entryPoint }, triggered);
    (0, proto_1.renameIfPresent)(parsed, ep, "serviceAccount", "serviceAccountEmail");
    (0, proto_1.copyIfPresent)(parsed, ep, "availableMemoryMb", "cpu", "maxInstances", "minInstances", "concurrency", "timeoutSeconds", "vpc", "labels", "ingressSettings", "environmentVariables", "serviceAccount");
    (0, proto_1.convertIfPresent)(parsed, ep, "secretEnvironmentVariables", (senvs) => {
        if (!senvs) {
            return null;
        }
        return senvs.map(({ key, secret }) => {
            return { key, secret: secret || key, projectId: project };
        });
    });
    return parsed;
}
function parseEndpoints(manifest, id, project, defaultRegion, runtime) {
    const allParsed = [];
    const prefix = `endpoints[${id}]`;
    const ep = manifest.endpoints[id];
    assertManifestEndpoint(ep, id);
    for (const region of ep.region || [defaultRegion]) {
        let triggered;
        if (backend.isEventTriggered(ep)) {
            const eventTrigger = {
                eventType: ep.eventTrigger.eventType,
                retry: false,
            };
            (0, proto_1.renameIfPresent)(eventTrigger, ep.eventTrigger, "serviceAccount", "serviceAccountEmail");
            (0, proto_1.copyIfPresent)(eventTrigger, ep.eventTrigger, "eventFilterPathPatterns", "retry", "serviceAccount", "region");
            (0, proto_1.convertIfPresent)(eventTrigger, ep.eventTrigger, "channel", (c) => resolveChannelName(project, c, defaultRegion));
            (0, proto_1.convertIfPresent)(eventTrigger, ep.eventTrigger, "eventFilters", (filters) => {
                const copy = Object.assign({}, filters);
                if (copy["topic"] && !copy["topic"].startsWith("projects/")) {
                    copy["topic"] = `projects/${project}/topics/${copy["topic"]}`;
                }
                return copy;
            });
            triggered = { eventTrigger };
        }
        else if (backend.isHttpsTriggered(ep)) {
            triggered = { httpsTrigger: {} };
            (0, proto_1.copyIfPresent)(triggered.httpsTrigger, ep.httpsTrigger, "invoker");
        }
        else if (backend.isCallableTriggered(ep)) {
            triggered = { callableTrigger: {} };
        }
        else if (backend.isScheduleTriggered(ep)) {
            triggered = { scheduleTrigger: ep.scheduleTrigger };
        }
        else if (backend.isTaskQueueTriggered(ep)) {
            triggered = { taskQueueTrigger: ep.taskQueueTrigger };
        }
        else if (backend.isBlockingTriggered(ep)) {
            triggered = { blockingTrigger: ep.blockingTrigger };
        }
        else {
            throw new error_1.FirebaseError(`Do not recognize trigger type for endpoint ${id}. Try upgrading ` +
                "firebase-tools with npm install -g firebase-tools@latest");
        }
        (0, parsing_1.requireKeys)(prefix, ep, "entryPoint");
        const parsed = Object.assign({ platform: ep.platform || "gcfv2", id,
            region,
            project,
            runtime, entryPoint: ep.entryPoint }, triggered);
        (0, proto_1.renameIfPresent)(parsed, ep, "serviceAccount", "serviceAccountEmail");
        (0, proto_1.copyIfPresent)(parsed, ep, "availableMemoryMb", "maxInstances", "minInstances", "concurrency", "serviceAccount", "timeoutSeconds", "vpc", "labels", "ingressSettings", "environmentVariables", "cpu");
        (0, proto_1.convertIfPresent)(parsed, ep, "secretEnvironmentVariables", (senvs) => {
            if (!senvs) {
                return null;
            }
            return senvs.map(({ key, secret }) => {
                return { key, secret: secret || key, projectId: project };
            });
        });
        allParsed.push(parsed);
    }
    return allParsed;
}
function resolveChannelName(projectId, channel, defaultRegion) {
    if (!channel.includes("/")) {
        const location = defaultRegion;
        const channelId = channel;
        return "projects/" + projectId + "/locations/" + location + "/channels/" + channelId;
    }
    const match = CHANNEL_NAME_REGEX.exec(channel);
    if (!(match === null || match === void 0 ? void 0 : match.groups)) {
        throw new error_1.FirebaseError("Invalid channel name format.");
    }
    const matchedProjectId = match.groups.project;
    const location = match.groups.location;
    const channelId = match.groups.channel;
    if (matchedProjectId) {
        return "projects/" + matchedProjectId + "/locations/" + location + "/channels/" + channelId;
    }
    else {
        return "projects/" + projectId + "/locations/" + location + "/channels/" + channelId;
    }
}
